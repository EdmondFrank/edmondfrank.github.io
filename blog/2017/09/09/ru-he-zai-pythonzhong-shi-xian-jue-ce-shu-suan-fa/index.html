
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="ja"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>如何在Python中实现决策树算法 - EdmondFrank's 时光足迹</title>
  <meta name="author" content="EdmondFrank">

  
  <meta name="description" content="如何在Python中实现决策树算法 决策树算法是一种简单的预测算法，但正是因为它模型的简单性，常作为一些高级的组合算法的基础，例如bagging，random forests ，gradient boosting 等等。再者，由于决策树的最终模型和预估行为具有较强的业务相关与可解析性， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://edmondfrank.github.io/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="EdmondFrank's 时光足迹" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.cat.net/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>
  
  

</head>

<body >
  <div id="container">
    <header role="banner"><hgroup>
  <h1><a href="/">EdmondFrank's 时光足迹</a></h1>
  
    <h2>この先は暗い夜道だけかもしれない　それでも信じて進むんだ。星がその道を少しでも照らしてくれるのを。<br>或许前路永夜，即便如此我也要前进，因为星光即使微弱也会我为照亮前途。<br>——《四月は君の嘘》</h2>
  
</hgroup>

</header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:edmondfrank.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
</ul>

</nav>
    <div id="main">
      <div id="content">
        <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title"><a href="">如何在Python中实现决策树算法</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-09T15:33:50+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


<div class="entry-content"><h1 id="如何在python中实现决策树算法">如何在Python中实现决策树算法</h1>




<p>决策树算法是一种简单的预测算法，但正是因为它模型的简单性，常作为一些高级的组合算法的基础，例如<strong>bagging，random forests ，gradient boosting</strong> 等等。再者，由于决策树的最终模型和预估行为具有较强的业务相关与可解析性，使得它十分受从业者与领域专家的欢迎，在各行各业中也有十分多的应用。</p>




<h4 id="决策树的优缺点">决策树的优缺点</h4>




<p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据</p>




<p>缺点：可能会产生过拟合问题</p>




<h2 id="决策树的构建">决策树的构建</h2>




<p>在构建决策树之前，我们首先要明确的第一个问题就是：在当前的数据集上哪个特征在划分数据分类时起决定性作用。而其中划分数据集的最大原则就是：<strong><em>将无序的数据变得更加有序。</em></strong></p>




<p>在选择如何去划分数据集的时候，我们可以采用各种不同的方法。但是每种方法都有各自的优缺点。组织杂乱无章的数据的一种方法就是使用信息论度量信息。</p>




<p>在划分数据集之前之后信息发生的变化称为<strong>信息增益</strong>，而获得信息增益最高的特征就是我们用于划分数据的最好选择。</p>




<p>在评测哪种数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益，而为了能够计算和理解信息增益，我们又必须先了解一个概念，即：集合信息的度量方式，其被称为<strong>香农熵</strong>或简称<strong>熵</strong>。这个名字来源于信息论之父<a href="https://baike.baidu.com/item/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E8%89%BE%E5%B0%94%E4%BC%8D%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C/10588593?fr=aladdin&amp;fromid=1146248&amp;fromtitle=%E9%A6%99%E5%86%9C">克劳德×香农</a></p>




<p>熵：被定义为信息的<strong>期望值</strong>，如果一个事件发生的概率是<script type="math/tex" id="MathJax-Element-1">p(x)</script>,则其信息熵为:</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-2">H(X)=-\sum _{i=i}^n p(x_i) \log  \left (p (x_i)\right)</script></p>
  
  <p>Eg:<img src="http://www.saedsayad.com/images/Entropy_3.png" alt="enter image description here" title=""></p>
</blockquote>




<p>其中n是分类的数目。</p>




<p>可以这样验证一下：如果这件事发生的概率是1，其信息熵<script type="math/tex" id="MathJax-Element-3">H</script>则等于0，因为你知道他一定会发生，丝毫不会觉得惊喜;但是如果这件事的概率趋向于无穷小，比如国足夺得世界杯冠军，那么他的信息熵就会趋向于无穷大。就像你心中听完上一条信息之后，心中可能就有数十万只草泥马奔过一样。</p>




<h4 id="使用python计算信息的熵">使用Python计算信息的熵</h4>




<p>下面我们将以《机器学习实战》一书中给出的例子为基础进一步探讨本文所讲内容。</p>




<blockquote>
  <p><strong>海洋生物数据表</strong></p>
  
  <table>
<thead>
<tr>
  <th>index</th>
  <th>不浮出水面是否可以生存</th>
  <th>是否有脚蹼</th>
  <th>是否属于鱼类</th>
</tr>
</thead>
<tbody><tr>
  <td>0</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>1</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>2</td>
  <td>是</td>
  <td>否</td>
  <td>否</td>
</tr>
<tr>
  <td>3</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
<tr>
  <td>4</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
</tbody></table>

</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#coding:utf-8</span>
</span><span class='line'><span class="c"># 代码功能：计算香农熵，本代码来源于书籍《机器学习实战》</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span> <span class="c">#我们要用到对数函数，所以我们需要引入math模块中定义好的log函数（对数函数）</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span><span class="c">#传入数据集</span>
</span><span class='line'><span class="c"># 在这里dataSet是一个链表形式的的数据集</span>
</span><span class='line'>    <span class="n">countDataSet</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span> <span class="c"># 我们计算出这个数据集中的数据个数，在这里我们的值是5个数据集</span>
</span><span class='line'>    <span class="n">labelCounts</span><span class="o">=</span><span class="p">{}</span> <span class="c"># 构建字典，用键值对的关系我们表示出 我们数据集中的类别还有对应的关系</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span> <span class="c">#通过for循环，我们每次取出一个数据集，如featVec=[1,1,&#39;yes&#39;]</span>
</span><span class='line'>        <span class="n">currentLabel</span><span class="o">=</span><span class="n">featVec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c"># 取出最后一列 也就是类别的那一类，比如说‘yes’或者是‘no’</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">currentLabel</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">shannonEnt</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c"># 计算香农熵， 根据公式</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="p">:</span>
</span><span class='line'>        <span class="n">prob</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">labelCounts</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">/</span><span class="n">countDataSet</span>
</span><span class='line'>        <span class="n">shannonEnt</span> <span class="o">-=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">shannonEnt</span>
</span><span class='line'><span class="k">def</span> <span class="nf">createDataSet</span><span class="p">():</span>
</span><span class='line'>    <span class="n">dataSet</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">]]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;no surfacing&#39;</span><span class="p">,</span><span class="s">&#39;flippers&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">dataSet</span><span class="p">,</span> <span class="n">labels</span>
</span><span class='line'>
</span><span class='line'><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span> <span class="o">=</span> <span class="n">createDataSet</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘yes’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  [‘no surfacing’, ‘flippers’] <br>
  0.9709505944546686</p>
</blockquote>




<p>其中，香农熵越高，则代表混合的数据越多，这点我们可以通过在数据集中添加更多的分类来验证。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">myDat</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s">&#39;maybe&#39;</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  1.3709505944546687</p>
</blockquote>




<h4 id="划分数据集">划分数据集</h4>




<p>分类算法除了需要测量信息熵之外，还需要划分数据集，度量划分数据集的熵，以便判断当前是否正确地划分了数据集。</p>




<p>那么，我们如何确定目前划分数据的方法是否就是最优的划分方法呢？答案就是：<strong>信息增益</strong>。我们仅需选择使得划分后数据集信息增益最大的特征作为分类的最佳特征即可。</p>




<p>首先假设我们选取了第一个特征<strong>“是否需要浮出水面生存”</strong>的第一种可能<strong>“是”</strong>来划分数据集，我们得到划分之后的数据集就是：</p>




<blockquote>
  <p>[[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’]</p>
</blockquote>




<p><strong>“否”</strong>的话，得到的划分集则是：</p>




<blockquote>
  <p>[[0, 1, ‘no’], [0, 1, ‘no’]]</p>
</blockquote>




<p>其他特征的划分方式也以此类推。</p>




<p>知道如何划分数据集之后，让我们来构建我们下一步的数据划分代码。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 代码功能：划分数据集</span>
</span><span class='line'><span class="k">def</span> <span class="nf">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">axis</span><span class="p">,</span><span class="n">value</span><span class="p">):</span> <span class="c">#传入三个参数第一个参数是我们的数据集，是一个链表形式的数据集；第二个参数是我们的要依据某个特征来划分数据集</span>
</span><span class='line'>    <span class="n">retDataSet</span> <span class="o">=</span> <span class="p">[]</span> <span class="c">#由于参数的链表dataSet我们拿到的是它的地址，也就是引用，直接在链表上操作会改变它的数值，所以我们新建一格链表来做操作</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">:</span> <span class="c">#如果某个特征和我们指定的特征值相等</span>
</span><span class='line'>        <span class="c">#除去这个特征然后创建一个子特征</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span> <span class="o">=</span> <span class="n">featVec</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</span><span class='line'>            <span class="c">#将满足条件的样本并且经过切割后的样本都加入到我们新建立的样本中</span>
</span><span class='line'>            <span class="n">retDataSet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduceFeatVec</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">retDataSet</span>
</span></code></pre></td></tr></table></div></figure>




<p>下面来测试下我们的代码</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] [[1, ‘maybe’], [1, ‘yes’], [0, ‘no’]]</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out]  [[1, ‘no’], [1, ‘no’]]</p>
</blockquote>




<p>知道怎么划分数据集之后，我们接下来要做的就是遍历整个数据集的特征值，然后循环计算熵，找出最好的分类特征了。</p>




<h4 id="选择最好的数据划分方式">选择最好的数据划分方式</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
</span><span class='line'>    <span class="n">numFeatures</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="n">baseEntropy</span> <span class="o">=</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestInfoGain</span> <span class="o">=</span><span class="mf">0.0</span>
</span><span class='line'>    <span class="n">bestFeature</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numFeatures</span><span class="p">):</span>
</span><span class='line'>        <span class="n">featList</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>        <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featList</span><span class="p">)</span>
</span><span class='line'>        <span class="n">newEntropy</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>            <span class="n">subDataSet</span> <span class="o">=</span> <span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">value</span><span class="p">)</span>
</span><span class='line'>            <span class="n">prob</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
</span><span class='line'>            <span class="n">newEntropy</span> <span class="o">+=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">infoGain</span> <span class="o">=</span> <span class="n">baseEntropy</span> <span class="o">-</span> <span class="n">newEntropy</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span><span class="p">(</span><span class="n">infoGain</span> <span class="o">&gt;</span> <span class="n">bestInfoGain</span><span class="p">):</span>
</span><span class='line'>            <span class="n">bestInfoGain</span> <span class="o">=</span> <span class="n">infoGain</span>
</span><span class='line'>            <span class="n">bestFeature</span> <span class="o">=</span> <span class="n">i</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">bestFeature</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的choseBestFeatureToSplit()函数的使用是需要满足一定条件的： <br>
1.  数据必须是一种有列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度。 <br>
2. 数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签 </p>




<p>接下来，我们来运行choseBestFeatureToSplit()函数来计算出最佳分类特征。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] 0</p>
</blockquote>




<p>从这里我们可以得到第0个特征是最好用于划分数据集的特征。确实，这个分类特征的选择就我们目测而言也是最好的选择。</p>




<p>知道如何选取特征之后，下一步我们就要如何将上面的函数有机结合在一起构建出决策树。</p>




<h4 id="处理特殊情况">处理特殊情况</h4>




<p>工作原理： <br>
1.  得到原始数据集 <br>
2. 基于最好的属性值划分数据集 <br>
3.  由于特征值不止一个，将划分后的数据传递到树分支的下一个节点，再重复2操作 <br>
4. 程序遍历完所有划分数据集属性或每个分支下所有实例都具有相同分类后结束</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">):</span> <span class="c"># 传入的参数是已经划分完所有特征之后剩余的数据集，</span>
</span><span class='line'>    <span class="c">#例如[[&#39;yes&#39;],[&#39;yes&#39;],[&#39;maybe&#39;]]</span>
</span><span class='line'>    <span class="n">classCount</span><span class="o">=</span><span class="p">{}</span> <span class="c">#创建一个字典</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">vote</span> <span class="ow">in</span> <span class="n">classList</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">vote</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">classCount</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="c"># 根据上述的语句，以及我们的例子，我们最终可以得到的结果如下： {&#39;yes&#39;:2,&#39;maybe&#39;:1}</span>
</span><span class='line'>        <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="c">#这个语句比较复杂，我们在下面详细讲解一下。</span>
</span><span class='line'><span class="c"># 使用字典iteritems</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的majorityCnt()函数是为了处理<strong>特殊分类</strong>而存在的。我们知道如果根据特征来划分属性，每划分一次就会消耗一个特征，如果我们使用完了所有的特征但是类别还没有划分完那我们就可以采用多数表决的方法来确定叶子节点了。</p>




<p>在上面的代码中，我们发现最后我们用排序函数对剩余的类作了降序处理，并只返回了分类个数最多的元素的那个类。这是一种折中的方法，因为对于一些已经使用完特征的数据集，我们不可能清楚地将一些类分离出来，我们就只能统计其中数量最多的那个分类，以次划分。</p>




<h4 id="递归构建决策树">递归构建决策树</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">createTree</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">classList</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="n">classList</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span> <span class="p">(</span><span class="n">classList</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">bestFeat</span> <span class="o">=</span> <span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestFeatLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">myTree</span> <span class="o">=</span> <span class="p">{</span><span class="n">bestFeatLabel</span><span class="p">:{}}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">del</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">bestFeatL</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">featValues</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featValues</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>        <span class="n">subLabels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:]</span>
</span><span class='line'>        <span class="n">myTree</span><span class="p">[</span><span class="n">bestFeatLabel</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">createTree</span><span class="p">(</span><span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">bestFeat</span><span class="p">,</span><span class="n">value</span><span class="p">),</span><span class="n">subLabels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">myTree</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，我们来运行我们的代码来构建出一棵决策树看看。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">createTree</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  [‘no surfacing’, ‘flippers’] <br>
  0 <br>
  no surfacing <br>
  [‘flippers’] <br>
  0 <br>
  flippers <br>
  {‘no surfacing’: {0: ‘no’, 1: {‘flippers’: {0: ‘no’, 1: ‘yes’}}}}</p>
</blockquote>




<p>根据返回的结果，我们可以画出以下的决策树。 <br>
<img src="https://i.loli.net/2017/09/09/59b397d98b6e3.png" alt="dt.png" title=""></p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">EdmondFrank</span></span>

      








  



<time datetime="2017-09-09T15:33:50+08:00" pubdate data-updated="true"></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  <a href="https://twitter.com/share" class="twitter-share-button" data-url="https://edmondfrank.github.io/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/" data-via="EdmondFrank4" data-counturl="https://edmondfrank.github.io/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2017/09/05/laplacebian-huan/" title="Previous Post: Laplace变换">&laquo; Laplace变换</a>
      
      
        <a class="basic-alignment right" href="/blog/2017/09/14/geekde-xie-zuo-fang-shi-latex-ru-men/" title="Next Post: Geek的写作方式——LaTeX 入门">Geek的写作方式——LaTeX 入门 &raquo;</a>
      
    </p>
  </footer>
</article>


</div>

      </div><!-- /div#content -->
    </div><!-- /div#main -->
  </div><!-- /div.container -->
  <footer><div id="footer-widgets-wrapper">
  <div id="footer-first" class="footer-widget">
    <h3>About Me</h3>
    <section class="about-me">
      
        <img class="icon-image" src="https://avatars0.githubusercontent.com/u/13914416?s=240" alt="icon_image">
      
      <div>
        <ul>
          
            <li>GitHub: <a href="https://github.com/EdmondFrank">@EdmondFrank</a></li>
          
          
            <li>Twitter: <a href="https://twitter.com/EdmondFrank4">@EdmondFrank4</a></li>
          
            <li>Blog: <a href="https://edmondfrank.github.io">https://edmondfrank.github.io</a></li>
        </ul>
        <p>
          この町、冗談と気まぐれと偶然でてきっているらしい。
        </p>
      </div>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-second" class="footer-widget">
    <h3>Recent Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Recent Posts";
        Hatena.BookmarkWidget.sort  = "hot";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-third" class="footer-widget">
    <h3>Popular Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Popular Posts";
        Hatena.BookmarkWidget.sort  = "count";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-third -->
</div><!-- /div#footer-widgets-wrapper -->

<div id="credit" role="contentinfo">
  <p>
    Copyright &copy; 2019 - <a href="https://github.com/EdmondFrank/">EdmondFrank</a> -
    <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  </p>
</div>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
