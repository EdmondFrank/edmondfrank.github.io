
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="ja"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>传统机器学习走向神经网络 - EdmondFrank's 时光足迹</title>
  <meta name="author" content="EdmondFrank">

  
  <meta name="description" content="﻿传统机器学习走向神经网络 神经网络的基本结构 首先我们先来看一下最基础的神经网络结构： 由上图的结构可以看出，这个神经网络具有三层，其中输入层不计。而中间的橙色层则为两层隐藏层，最右的蓝色层为输出层。输入从最左边的输入层进行输入，然后经过两次隐藏层和激活函数之后进行输出， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://edmondfrank.github.io/blog/2017/12/14/chuan-tong-ji-qi-xue-xi-zou-xiang-shen-jing-wang-luo/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="EdmondFrank's 时光足迹" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.cat.net/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>
  
  

</head>

<body >
  <div id="container">
    <header role="banner"><hgroup>
  <h1><a href="/">EdmondFrank's 时光足迹</a></h1>
  
    <h2>この先は暗い夜道だけかもしれない　それでも信じて進むんだ。星がその道を少しでも照らしてくれるのを。<br>或许前路永夜，即便如此我也要前进，因为星光即使微弱也会我为照亮前途。<br>——《四月は君の嘘》</h2>
  
</hgroup>

</header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:edmondfrank.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
</ul>

</nav>
    <div id="main">
      <div id="content">
        <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title"><a href="">传统机器学习走向神经网络</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-12-14T23:43:13+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


<div class="entry-content"><p>﻿<h1 id="传统机器学习走向神经网络">传统机器学习走向神经网络</h1></p>

<h2 id="神经网络的基本结构">神经网络的基本结构</h2>




<p>首先我们先来看一下最基础的神经网络结构： <br>
<img src="https://ws1.sinaimg.cn/large/a3d23450gy1fmgm7cftunj20kf0ckaep.jpg" alt="" title=""></p>




<p>由上图的结构可以看出，这个神经网络具有三层，其中输入层不计。而中间的橙色层则为两层隐藏层，最右的蓝色层为输出层。输入从最左边的输入层进行输入，然后经过两次隐藏层和激活函数之后进行输出，这样我们可以把这个神经网络简单地表示成一下的式子： <br>
<script type="math/tex; mode=display" id="MathJax-Element-82">Y_{out} = W_iX_{in}+B</script> <br>
W为X的权重，而B为函数的偏置。 <br>
其中，偏置值B的存在有利于打破数据对称的局面，使得神经网络可以应用在非对称的数据之上。</p>




<h2 id="神经网络的基本算法">神经网络的基本算法</h2>




<p>前向传导：前向传导的思想比较简单，下面的一张图足以概括它的主要思想。 <br>
<img src="https://ws1.sinaimg.cn/large/a3d23450gy1fmgp39x2ltj20oh0gydi9.jpg" alt="" title=""></p>




<p>反向传播：反向传播的方法其实也比较简单，其主要思想是涉及求偏导，以及链式求导法则。 <br>
<img src="https://ws1.sinaimg.cn/large/a3d23450gy1fmgp6qj2wlj20mj0i441b.jpg" alt="" title=""></p>




<p>梯度下降：梯度下降法是一个最优化算法，通常也称为最速下降法。最速下降法是求解无约束优化问题最简单和最古老的方法之一，虽然现已不具有实用性，但是许多有效算法都是以它为基础进行改进和修正而得到的。最速下降法是用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。</p>




<h2 id="朴素贝叶斯和神经网络">朴素贝叶斯和神经网络</h2>




<p>首先朴素贝叶斯算法的原始形式可以表达成以下的形式： <br>
<script type="math/tex" id="MathJax-Element-1467">G(x)=arg\  max\ p(y)  
\prod\limits^n_{i=1}p(x_i|y)^{x_i}</script></p>




<p>除此之外，该算法还有一下特点： <br>
<script type="math/tex" id="MathJax-Element-1468">x_i只有0，1两种取值</script> <br>
<script type="math/tex" id="MathJax-Element-1469">x_i取1意味着x_i对应了的特征“出现了”</script>  <br>
<script type="math/tex" id="MathJax-Element-1470">x_i取0意味着x_i对应了的特征“没出现”</script></p>




<p>这样转换成矩阵的形式时，我们可以采用独热编码亦称One-hot Encode。 <br>
独热编码：</p>




<p>解决了分类标签的问题，那么我们又该怎样用神经网络的线性模型形式来表达贝叶斯公式中概率相乘的情况呢？</p>




<p>没错，就是使用对数函数。根据对数函数的性质<script type="math/tex" id="MathJax-Element-1471">log_2X+log_2Y=log_2XY</script>,我们就可以通过对数变换，将乘法转换成加法的形式，我们可以把上面的朴素贝叶斯公式改写成： <br>
<script type="math/tex" id="MathJax-Element-1472">G(x)=arg\ max\ log(y)+\sum\limits^n_{i=1}x_ilog\ p(x_i|y)</script></p>




<p>那么我们就可以用退化成线性模型的神经网络来实现朴素贝叶斯模型。</p>




<h3 id="核心实现">核心实现</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 独热化处理部分</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
</span><span class='line'><span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
</span><span class='line'><span class="n">x_train</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</span><span class='line'><span class="n">x_test</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c">## .....篇幅有限,此处省略其余代码</span>
</span><span class='line'>
</span><span class='line'><span class="c"># NaiveBayes -&gt; NN 权值转换部分</span>
</span><span class='line'><span class="k">class</span> <span class="nc">NB2NN</span><span class="p">(</span><span class="n">TransformationBase</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="nb">super</span><span class="p">(</span><span class="n">NB2NN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_name_appendix</span> <span class="o">=</span> <span class="s">&quot;NaiveBayes&quot;</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">model_param_settings</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s">&quot;activations&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_units</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_all_data</span><span class="p">()</span>
</span><span class='line'>        <span class="n">nb</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
</span><span class='line'>        <span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_print_model_performance</span><span class="p">(</span><span class="n">nb</span><span class="p">,</span> <span class="s">&quot;Naive Bayes&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_ws</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">.</span><span class="n">feature_log_prob_</span><span class="o">.</span><span class="n">T</span><span class="p">]</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_bs</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">.</span><span class="n">class_log_prior_</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>




<h2 id="决策树贝叶斯和神经网络">决策树贝叶斯和神经网络</h2>




<p>首先，决策树的原理主要就是通过数据信息熵的变化来选择当前的最优分类点，然后从根开始一步一步扩展成树。而实质上，最后成功构建出来的决策树，其从根节点开始到每个分类叶子节点的路径对应的都是一组高维空间上的超平面组合。决策树的分类也就是用一组超平面去划分数据空间，使得最后剩下一个唯一确定的标识。</p>




<p>知道决策树的本质之后，我们就可以用这样的方法来将决策树算法迁移到神经网络上： <br>
* 第一个隐藏层表达决策树的中间节点所对应的超平面 <br>
* 第二个隐藏层表达各个决策的路径 <br>
* 第二个隐藏层和输出层之间的权值矩阵表达各个叶节点</p>




<h3 id="核心实现-1">核心实现</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">## 因为决策树到神经网络的转换较为复杂,此处仅贴出核心代码</span>
</span><span class='line'><span class="k">class</span> <span class="nc">DT2NN</span><span class="p">(</span><span class="n">TransformationBase</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="nb">super</span><span class="p">(</span><span class="n">DT2NN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_name_appendix</span> <span class="o">=</span> <span class="s">&quot;DTree&quot;</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">model_param_settings</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s">&quot;activations&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s">&quot;sign&quot;</span><span class="p">,</span> <span class="s">&quot;one_hot&quot;</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_all_data</span><span class="p">()</span>
</span><span class='line'>        <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
</span><span class='line'>        <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_print_model_performance</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="s">&quot;Decision Tree&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">tree_structure</span> <span class="o">=</span> <span class="n">export_structure</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</span><span class='line'>        <span class="n">n_leafs</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">tree_structure</span><span class="p">])</span>
</span><span class='line'>        <span class="n">n_internals</span> <span class="o">=</span> <span class="n">n_leafs</span> <span class="o">-</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">print</span><span class="p">(</span><span class="s">&quot;Internals : {} ; Leafs : {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_internals</span><span class="p">,</span> <span class="n">n_leafs</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_internals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span class='line'>        <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_internals</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span class='line'>        <span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_internals</span><span class="p">,</span> <span class="n">n_leafs</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span class='line'>        <span class="n">w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_leafs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_class</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span class='line'>        <span class="n">node_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="n">node_sign_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="n">node_id_cursor</span> <span class="o">=</span> <span class="n">leaf_id_cursor</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">max_route_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_units</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_internals</span><span class="p">,</span> <span class="n">n_leafs</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">for</span> <span class="n">depth</span><span class="p">,</span> <span class="n">feat_dim</span><span class="p">,</span> <span class="n">rs</span> <span class="ow">in</span> <span class="n">tree_structure</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">feat_dim</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span class='line'>                <span class="k">if</span> <span class="n">depth</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_list</span><span class="p">):</span>
</span><span class='line'>                    <span class="n">node_sign_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>                    <span class="n">node_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">node_id_cursor</span><span class="p">,</span> <span class="n">feat_dim</span><span class="p">,</span> <span class="n">rs</span><span class="p">])</span>
</span><span class='line'>                    <span class="n">w1</span><span class="p">[</span><span class="n">feat_dim</span><span class="p">,</span> <span class="n">node_id_cursor</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>                    <span class="n">b</span><span class="p">[</span><span class="n">node_id_cursor</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">rs</span>
</span><span class='line'>                    <span class="n">node_id_cursor</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>                <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                    <span class="n">node_list</span> <span class="o">=</span> <span class="n">node_list</span><span class="p">[:</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span><span class='line'>                    <span class="n">node_sign_list</span> <span class="o">=</span> <span class="n">node_sign_list</span><span class="p">[:</span><span class="n">depth</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="n">valid_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class='line'>                <span class="n">local_sign_list</span> <span class="o">=</span> <span class="n">node_sign_list</span><span class="p">[:]</span>
</span><span class='line'>                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">((</span><span class="n">node_id</span><span class="p">,</span> <span class="n">node_dim</span><span class="p">,</span> <span class="n">node_threshold</span><span class="p">),</span> <span class="n">node_sign</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
</span><span class='line'>                    <span class="nb">zip</span><span class="p">(</span><span class="n">node_list</span><span class="p">,</span> <span class="n">node_sign_list</span><span class="p">)</span>
</span><span class='line'>                <span class="p">):</span>
</span><span class='line'>                    <span class="n">valid_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">node_id</span><span class="p">,</span> <span class="n">node_sign</span><span class="p">))</span>
</span><span class='line'>                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>                        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">((</span><span class="n">local_id</span><span class="p">,</span> <span class="n">local_dim</span><span class="p">,</span> <span class="n">local_threshold</span><span class="p">),</span> <span class="n">local_sign</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
</span><span class='line'>                            <span class="n">node_list</span><span class="p">[:</span><span class="n">i</span><span class="p">],</span> <span class="n">local_sign_list</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
</span><span class='line'>                        <span class="p">)):</span>
</span><span class='line'>                            <span class="k">if</span> <span class="n">node_sign</span> <span class="o">==</span> <span class="n">local_sign</span> <span class="ow">and</span> <span class="n">node_dim</span> <span class="o">==</span> <span class="n">local_dim</span><span class="p">:</span>
</span><span class='line'>                                <span class="k">if</span> <span class="p">(</span>
</span><span class='line'>                                    <span class="p">(</span><span class="n">node_sign</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">node_threshold</span> <span class="o">&lt;</span> <span class="n">local_threshold</span><span class="p">)</span> <span class="ow">or</span>
</span><span class='line'>                                    <span class="p">(</span><span class="n">node_sign</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">node_threshold</span> <span class="o">&gt;</span> <span class="n">local_threshold</span><span class="p">)</span>
</span><span class='line'>                                <span class="p">):</span>
</span><span class='line'>                                    <span class="n">local_sign_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>                                    <span class="n">valid_nodes</span><span class="o">.</span><span class="n">remove</span><span class="p">((</span><span class="n">local_id</span><span class="p">,</span> <span class="n">local_sign</span><span class="p">))</span>
</span><span class='line'>                                    <span class="k">break</span>
</span><span class='line'>                <span class="k">for</span> <span class="n">node_id</span><span class="p">,</span> <span class="n">node_sign</span> <span class="ow">in</span> <span class="n">valid_nodes</span><span class="p">:</span>
</span><span class='line'>                    <span class="n">w2</span><span class="p">[</span><span class="n">node_id</span><span class="p">,</span> <span class="n">leaf_id_cursor</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_sign</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_nodes</span><span class="p">)</span>
</span><span class='line'>                <span class="n">max_route_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_route_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_nodes</span><span class="p">))</span>
</span><span class='line'>                <span class="n">w3</span><span class="p">[</span><span class="n">leaf_id_cursor</span><span class="p">]</span> <span class="o">=</span> <span class="n">rs</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span>
</span><span class='line'>                <span class="n">leaf_id_cursor</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">w2</span> <span class="o">*=</span> <span class="n">max_route_length</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_ws</span> <span class="o">=</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">w3</span><span class="p">]</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_transform_bs</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c">#................ 篇幅有限,省略其余代码</span>
</span><span class='line'>
</span><span class='line'><span class="c"># DTree -&gt; NN</span>
</span><span class='line'><span class="k">def</span> <span class="nf">export_structure</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
</span><span class='line'>    <span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
</span><span class='line'>        <span class="n">feature_dim</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">feature_dim</span> <span class="o">==</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">:</span>
</span><span class='line'>            <span class="k">yield</span> <span class="n">depth</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
</span><span class='line'>            <span class="k">yield</span> <span class="n">depth</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">,</span> <span class="n">threshold</span>
</span><span class='line'>            <span class="k">yield from</span> <span class="n">recurse</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>            <span class="k">yield</span> <span class="n">depth</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">,</span> <span class="n">threshold</span>
</span><span class='line'>            <span class="k">yield from</span> <span class="n">recurse</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">recurse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<h2 id="模型改进">模型改进</h2>




<h3 id="对于朴素贝叶斯">对于朴素贝叶斯</h3>




<p>根据上述的原理和理论，我们可以将朴素贝叶斯和决策树转换成神经网络模型，但是转换之后是否存在意义呢？</p>




<p><strong>首先</strong>本身可以通过简单log对数转换成线性模型的朴素贝叶斯算法来说，其转换的步骤并不复杂，但却能够对朴素贝叶斯的独立假设进行一定的微调修正。</p>




<h3 id="对于决策树">对于决策树</h3>




<p>那么对于决策树来说，神经网络的介入可以对决策树的硬边界作一定的修正和“软化”作用。</p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">EdmondFrank</span></span>

      








  



<time datetime="2017-12-14T23:43:13+08:00" pubdate data-updated="true"></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/shen-jing-wang-luo-yu-shen-du-xue-xi/'>神经网络与深度学习</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  <a href="https://twitter.com/share" class="twitter-share-button" data-url="https://edmondfrank.github.io/blog/2017/12/14/chuan-tong-ji-qi-xue-xi-zou-xiang-shen-jing-wang-luo/" data-via="EdmondFrank4" data-counturl="https://edmondfrank.github.io/blog/2017/12/14/chuan-tong-ji-qi-xue-xi-zou-xiang-shen-jing-wang-luo/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2017/12/08/shen-du-xue-xi-ru-men-jian-jie-(er-)/" title="Previous Post: 深度学习入门简介（二）">&laquo; 深度学习入门简介（二）</a>
      
      
        <a class="basic-alignment right" href="/blog/2017/12/21/zui-da-si-ran-gu-ji/" title="Next Post: 最大似然估计">最大似然估计 &raquo;</a>
      
    </p>
  </footer>
</article>


</div>

      </div><!-- /div#content -->
    </div><!-- /div#main -->
  </div><!-- /div.container -->
  <footer><div id="footer-widgets-wrapper">
  <div id="footer-first" class="footer-widget">
    <h3>About Me</h3>
    <section class="about-me">
      
        <img class="icon-image" src="https://avatars0.githubusercontent.com/u/13914416?s=240" alt="icon_image">
      
      <div>
        <ul>
          
            <li>GitHub: <a href="https://github.com/EdmondFrank">@EdmondFrank</a></li>
          
          
            <li>Twitter: <a href="https://twitter.com/EdmondFrank4">@EdmondFrank4</a></li>
          
            <li>Blog: <a href="https://edmondfrank.github.io">https://edmondfrank.github.io</a></li>
        </ul>
        <p>
          この町、冗談と気まぐれと偶然でてきっているらしい。
        </p>
      </div>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-second" class="footer-widget">
    <h3>Recent Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Recent Posts";
        Hatena.BookmarkWidget.sort  = "hot";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-third" class="footer-widget">
    <h3>Popular Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Popular Posts";
        Hatena.BookmarkWidget.sort  = "count";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-third -->
</div><!-- /div#footer-widgets-wrapper -->

<div id="credit" role="contentinfo">
  <p>
    Copyright &copy; 2022 - <a href="https://github.com/EdmondFrank/">EdmondFrank</a> -
    <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  </p>
</div>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
